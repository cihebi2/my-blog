---
title: "GraphRAG å®Œæ•´å…¥é—¨æŒ‡å—ï¼ˆä¸‰ï¼‰ï¼šå·¥å…·æ¡†æ¶æ·±åº¦åˆ†æ"
author: "Ciheb"
pubDatetime: 2024-07-04T10:24:22Z
description: "è¯¦ç»†åˆ†æNeo4jã€LangChainå’ŒMicrosoft GraphRAGç­‰ä¸»æµå·¥å…·æ¡†æ¶çš„ç‰¹ç‚¹ã€ä½¿ç”¨æ–¹æ³•å’Œæœ€ä½³å®è·µ"
tags: ["GraphRAG", "Neo4j", "LangChain", "Microsoft GraphRAG", "å·¥å…·æ¡†æ¶", "æŠ€æœ¯é€‰å‹"]
featured: true
draft: false
---

## å‰è¨€

åœ¨å‰ä¸¤ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬åˆ†åˆ«ä»‹ç»äº†GraphRAGçš„[åŸºç¡€æ¦‚å¿µ](./graphrag-complete-guide-part1)å’Œ[æ ¸å¿ƒæŠ€æœ¯](./graphrag-complete-guide-part2)ã€‚æœ¬ç¯‡å°†æ·±å…¥åˆ†æä¸»æµçš„GraphRAGå·¥å…·æ¡†æ¶ï¼Œå¸®åŠ©ä½ æ ¹æ®å®é™…éœ€æ±‚é€‰æ‹©åˆé€‚çš„æŠ€æœ¯æ ˆã€‚

> **ğŸ“‹ ç³»åˆ—å¯¼èˆª**ï¼š
> - [ç¬¬ä¸€ç¯‡ï¼šåŸºç¡€æ¦‚å¿µä¸æ ¸å¿ƒä¼˜åŠ¿](./graphrag-complete-guide-part1)
> - [ç¬¬äºŒç¯‡ï¼šæ ¸å¿ƒæŠ€æœ¯æ·±åº¦è§£æ](./graphrag-complete-guide-part2)
> - **ç¬¬ä¸‰ç¯‡ï¼šå·¥å…·æ¡†æ¶æ·±åº¦åˆ†æï¼ˆå½“å‰ï¼‰**
> - ç¬¬å››ç¯‡ï¼šåº”ç”¨å®è·µä¸å­¦ä¹ è·¯å¾„ï¼ˆå³å°†å‘å¸ƒï¼‰

## å·¥å…·æ¡†æ¶æ·±åº¦åˆ†æ

### Neo4jï¼šä¼ä¸šçº§å›¾æ•°æ®åº“çš„é¦–é€‰

Neo4jæ˜¯ç›®å‰æœ€æˆç†Ÿçš„å›¾æ•°æ®åº“ï¼Œå…¶**åŸç”Ÿå›¾å­˜å‚¨**æ¶æ„ä¸“ä¸ºå›¾æ•°æ®ä¼˜åŒ–ã€‚æ¯ä¸ªèŠ‚ç‚¹ç›´æ¥å­˜å‚¨åˆ°ç›¸é‚»èŠ‚ç‚¹çš„å¼•ç”¨ï¼Œä½¿å¾—å…³ç³»éå†æå…¶é«˜æ•ˆã€‚

#### åœ¨GraphRAGä¸­çš„æ ¸å¿ƒä¼˜åŠ¿

**1. CypheræŸ¥è¯¢è¯­è¨€**

Cypherä½¿ç”¨ç›´è§‚çš„ASCIIè‰ºæœ¯è¯­æ³•ï¼Œå¦‚`(èŠ‚ç‚¹)-[:å…³ç³»]->(èŠ‚ç‚¹)`ï¼Œè®©å¤æ‚çš„å›¾æŸ¥è¯¢å˜å¾—ç®€å•æ˜“è¯»ã€‚

```cypher
// å¤šè·³æ¨ç†æŸ¥è¯¢ç¤ºä¾‹ï¼šæŸ¥æ‰¾è‹¹æœå…¬å¸çš„ç«äº‰å¯¹æ‰‹çš„äº§å“
MATCH (apple:Company {name: "è‹¹æœå…¬å¸"})
      -[:COMPETES_WITH]->(competitor:Company)
      -[:PRODUCES]->(product:Product)
RETURN competitor.name, product.name
ORDER BY competitor.importance_score DESC
LIMIT 10
```

> **ğŸ“š çŸ¥è¯†ç‚¹æ³¨é‡Š**ï¼šASCIIè‰ºæœ¯è¯­æ³•æ˜¯æŒ‡ç”¨æ™®é€šå­—ç¬¦ç»„æˆçš„å›¾å½¢ï¼Œåœ¨Cypherä¸­ç”¨åœ†æ‹¬å·è¡¨ç¤ºèŠ‚ç‚¹ï¼Œæ–¹æ‹¬å·è¡¨ç¤ºå…³ç³»ï¼Œç®­å¤´è¡¨ç¤ºæ–¹å‘ã€‚

**2. é«˜æ€§èƒ½éå†**

Neo4jçš„æ€§èƒ½ä¼˜åŠ¿åœ¨å¤æ‚å…³ç³»æŸ¥è¯¢ä¸­æœ€ä¸ºæ˜æ˜¾ï¼š

```cypher
// æŸ¥æ‰¾å½±å“åŠ›ä¼ æ’­è·¯å¾„ï¼ˆ3è·³ä»¥å†…ï¼‰
MATCH path = (start:Person {name: "å²è’‚å¤«Â·ä¹”å¸ƒæ–¯"})
             -[:INFLUENCES*1..3]->(end:Person)
WHERE end.industry = "ç§‘æŠ€"
RETURN path, length(path) as influence_depth
ORDER BY influence_depth, end.importance_score DESC
```

**3. çµæ´»Schema**

Neo4jæ”¯æŒåŠ¨æ€æ·»åŠ æ–°çš„å®ä½“ç±»å‹å’Œå…³ç³»ç±»å‹ï¼Œéå¸¸é€‚åˆçŸ¥è¯†å›¾è°±çš„è¿­ä»£å‘å±•ï¼š

```cypher
// åŠ¨æ€æ·»åŠ æ–°çš„å®ä½“ç±»å‹å’Œå±æ€§
MERGE (entity:NewEntityType {
    name: $entity_name,
    description: $description,
    confidence: $confidence,
    created_at: datetime()
})

// åˆ›å»ºæ–°çš„å…³ç³»ç±»å‹
MATCH (source), (target)
WHERE source.id = $source_id AND target.id = $target_id
MERGE (source)-[r:NEW_RELATION_TYPE {
    weight: $weight,
    evidence: $evidence
}]->(target)
```

**4. ä¼ä¸šçº§ç‰¹æ€§**

- **å®‰å…¨æ€§**ï¼šç»†ç²’åº¦çš„è®¿é—®æ§åˆ¶å’Œæ•°æ®åŠ å¯†
- **å¤‡ä»½æ¢å¤**ï¼šå®Œæ•´çš„æ•°æ®å¤‡ä»½å’Œç¾éš¾æ¢å¤æ–¹æ¡ˆ
- **ç›‘æ§å‘Šè­¦**ï¼šå®æ—¶æ€§èƒ½ç›‘æ§å’Œè‡ªåŠ¨å‘Šè­¦
- **é›†ç¾¤éƒ¨ç½²**ï¼šæ”¯æŒé«˜å¯ç”¨å’Œè´Ÿè½½å‡è¡¡

#### Neo4jåœ¨GraphRAGä¸­çš„å®é™…åº”ç”¨æ¨¡å¼

**æ¨¡å¼1ï¼šå®ä½“ä¸­å¿ƒè®¾è®¡**

```cypher
// åˆ›å»ºå®ä½“èŠ‚ç‚¹
CREATE (entity:Entity {
    id: $entity_id,
    name: $name,
    type: $entity_type,
    description: $description,
    importance_score: $importance,
    confidence: $confidence,
    created_at: datetime(),
    updated_at: datetime()
})

// æ·»åŠ å®ä½“å±æ€§
MATCH (e:Entity {id: $entity_id})
SET e += $properties
```

**æ¨¡å¼2ï¼šæ–‡æ¡£é“¾æ¥è®¾è®¡**

```cypher
// å°†å®ä½“ä¸æºæ–‡æ¡£å…³è”
MATCH (entity:Entity {id: $entity_id})
MERGE (doc:Document {id: $doc_id})
MERGE (entity)-[:MENTIONED_IN {
    frequency: $frequency,
    context: $context
}]->(doc)
```

**æ¨¡å¼3ï¼šç¤¾åŒºæ£€æµ‹é›†æˆ**

```cypher
// ä½¿ç”¨Neo4jçš„å›¾æ•°æ®ç§‘å­¦åº“è¿›è¡Œç¤¾åŒºæ£€æµ‹
CALL gds.leiden.write('entity_graph', {
    writeProperty: 'community_id',
    relationshipWeightProperty: 'weight'
})
YIELD communityCount, modularity

// æŸ¥è¯¢ç¤¾åŒºä¿¡æ¯
MATCH (e:Entity)
WHERE e.community_id = $community_id
RETURN e.name, e.description, e.importance_score
ORDER BY e.importance_score DESC
```

#### æ€§èƒ½ä¼˜åŒ–æœ€ä½³å®è·µ

**1. ç´¢å¼•ç­–ç•¥**

```cypher
// ä¸ºé¢‘ç¹æŸ¥è¯¢çš„å±æ€§åˆ›å»ºç´¢å¼•
CREATE INDEX entity_name_index FOR (e:Entity) ON (e.name)
CREATE INDEX entity_type_index FOR (e:Entity) ON (e.type)
CREATE INDEX entity_importance_index FOR (e:Entity) ON (e.importance_score)

// åˆ›å»ºå¤åˆç´¢å¼•
CREATE INDEX entity_compound_index FOR (e:Entity) ON (e.type, e.importance_score)
```

**2. æŸ¥è¯¢ä¼˜åŒ–**

```cypher
// ä½¿ç”¨PROFILEåˆ†ææŸ¥è¯¢æ€§èƒ½
PROFILE
MATCH (start:Entity {name: $entity_name})
      -[r:RELATED_TO*1..3]-(end:Entity)
WHERE end.type IN $target_types
RETURN end
ORDER BY end.importance_score DESC
LIMIT 20
```

**3. å†…å­˜é…ç½®**

```ini
# neo4j.confé…ç½®ç¤ºä¾‹
dbms.memory.heap.initial_size=2G
dbms.memory.heap.max_size=8G
dbms.memory.pagecache.size=4G
dbms.tx_log.rotation.retention_policy=1 files
```

### LangChainï¼šæ¨¡å—åŒ–GraphRAGå¼€å‘æ¡†æ¶

LangChainæä¾›äº†ä¸°å¯Œçš„GraphRAGç»„ä»¶ï¼Œé€šè¿‡æ¨¡å—åŒ–è®¾è®¡ç®€åŒ–äº†å¼€å‘æµç¨‹ã€‚å…¶**é“¾å¼ç»„åˆ**çš„è®¾è®¡ç†å¿µä½¿å¾—å¼€å‘è€…èƒ½å¤Ÿå¿«é€Ÿæ„å»ºå¤æ‚çš„GraphRAGåº”ç”¨ã€‚

#### æ ¸å¿ƒç»„ä»¶æ¶æ„

**1. LLMGraphTransformerï¼šè‡ªåŠ¨å›¾æ„å»º**

```python
from langchain_experimental.graph_transformers import LLMGraphTransformer
from langchain_openai import ChatOpenAI

# åˆå§‹åŒ–å›¾è½¬æ¢å™¨
llm = ChatOpenAI(temperature=0, model_name="gpt-4")
transformer = LLMGraphTransformer(
    llm=llm,
    allowed_nodes=["Person", "Organization", "Technology", "Concept"],
    allowed_relationships=["WORKS_AT", "FOUNDED", "USES", "RELATED_TO"]
)

# ä»æ–‡æ¡£æ„å»ºå›¾
documents = [Document(page_content=text) for text in texts]
graph_documents = transformer.convert_to_graph_documents(documents)

# å­˜å‚¨åˆ°Neo4j
graph.add_graph_documents(graph_documents)
```

> **ğŸ’¡ æç¤º**ï¼šå…è®¸çš„èŠ‚ç‚¹å’Œå…³ç³»ç±»å‹å¯ä»¥æ ¹æ®é¢†åŸŸçŸ¥è¯†è¿›è¡Œå®šåˆ¶ï¼Œè¿™æ ·å¯ä»¥æé«˜æŠ½å–çš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ã€‚

**2. GraphCypherQAChainï¼šè‡ªç„¶è¯­è¨€æŸ¥è¯¢**

```python
from langchain.chains import GraphCypherQAChain

# åˆ›å»ºCypheræŸ¥è¯¢é“¾
cypher_chain = GraphCypherQAChain.from_llm(
    llm=llm,
    graph=graph,
    verbose=True,
    return_intermediate_steps=True
)

# è‡ªç„¶è¯­è¨€æŸ¥è¯¢
response = cypher_chain.run("è‹¹æœå…¬å¸çš„åˆ›å§‹äººéƒ½æœ‰è°ï¼Ÿ")
print(f"ç­”æ¡ˆ: {response}")

# æŸ¥çœ‹ç”Ÿæˆçš„CypheræŸ¥è¯¢
print(f"ç”Ÿæˆçš„Cypher: {cypher_chain.intermediate_steps}")
```

**3. VectorCypherRetrieverï¼šæ··åˆæ£€ç´¢**

```python
from langchain_community.vectorstores import Neo4jVector
from langchain_openai import OpenAIEmbeddings

# åˆ›å»ºå‘é‡ç´¢å¼•
vector_index = Neo4jVector.from_existing_graph(
    embeddings=OpenAIEmbeddings(),
    search_type="hybrid",  # æ··åˆæ£€ç´¢
    node_label="Document",
    text_node_properties=["text"],
    embedding_node_property="embedding"
)

# æ‰§è¡Œæ··åˆæ£€ç´¢
def hybrid_search(query, k=5):
    # å‘é‡æ£€ç´¢
    vector_results = vector_index.similarity_search(query, k=k)
    
    # å›¾æ£€ç´¢
    cypher_query = """
    MATCH (d:Document)-[:MENTIONS]->(e:Entity)
    WHERE e.name CONTAINS $query
    RETURN d.text, e.name, e.description
    LIMIT $k
    """
    graph_results = graph.query(cypher_query, {"query": query, "k": k})
    
    # ç»“æœèåˆ
    return merge_results(vector_results, graph_results)
```

#### å…¸å‹å¼€å‘æµç¨‹

**æ­¥éª¤1ï¼šæ•°æ®é¢„å¤„ç†**

```python
from langchain.text_splitter import RecursiveCharacterTextSplitter

# æ–‡æ¡£åˆ†å—
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200,
    length_function=len,
    separators=["\n\n", "\n", " ", ""]
)

documents = text_splitter.split_documents(raw_documents)
```

**æ­¥éª¤2ï¼šçŸ¥è¯†å›¾è°±æ„å»º**

```python
# é…ç½®å›¾è½¬æ¢å™¨
transformer = LLMGraphTransformer(
    llm=llm,
    # è‡ªå®šä¹‰æç¤ºæ¨¡æ¿
    node_properties=["description", "importance", "type"],
    relationship_properties=["strength", "evidence"]
)

# æ‰¹å¤„ç†è½¬æ¢
batch_size = 10
for i in range(0, len(documents), batch_size):
    batch = documents[i:i+batch_size]
    graph_docs = transformer.convert_to_graph_documents(batch)
    graph.add_graph_documents(graph_docs)
```

**æ­¥éª¤3ï¼šæ£€ç´¢å¢å¼ºè®¾ç½®**

```python
from langchain.chains import RetrievalQAWithSourcesChain

# åˆ›å»ºæ£€ç´¢å™¨
retriever = vector_index.as_retriever(
    search_type="mmr",  # æœ€å¤§è¾¹é™…ç›¸å…³æ€§
    search_kwargs={"k": 6, "fetch_k": 20}
)

# åˆ›å»ºQAé“¾
qa_chain = RetrievalQAWithSourcesChain.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=retriever,
    return_source_documents=True
)
```

#### LangChainçš„ä¼˜åŠ¿ä¸é™åˆ¶

**ä¼˜åŠ¿**ï¼š
- **å¿«é€ŸåŸå‹**ï¼šä¸°å¯Œçš„é¢„æ„å»ºç»„ä»¶ï¼Œå¿«é€Ÿæ­å»ºç³»ç»Ÿ
- **çµæ´»ç»„åˆ**ï¼šé“¾å¼è®¾è®¡ï¼Œæ˜“äºæ‰©å±•å’Œå®šåˆ¶
- **æ´»è·ƒç¤¾åŒº**ï¼šæ–‡æ¡£å®Œå–„ï¼Œç¤¾åŒºæ”¯æŒè‰¯å¥½
- **å¤šæ¨¡å‹æ”¯æŒ**ï¼šæ”¯æŒå¤šç§LLMå’ŒåµŒå…¥æ¨¡å‹

**é™åˆ¶**ï¼š
- **æ€§èƒ½ä¼˜åŒ–**ï¼šé«˜å±‚æŠ½è±¡å¯èƒ½å½±å“æ€§èƒ½è°ƒä¼˜
- **å¤æ‚æŸ¥è¯¢**ï¼šå¯¹äºéå¸¸å¤æ‚çš„å›¾æŸ¥è¯¢å¯èƒ½éœ€è¦è‡ªå®šä¹‰
- **ç‰ˆæœ¬ç¨³å®šæ€§**ï¼šå¿«é€Ÿè¿­ä»£å¯èƒ½å¯¼è‡´APIå˜åŒ–

### Microsoft GraphRAGï¼šå­¦æœ¯ç ”ç©¶çš„äº§ä¸šåŒ–å®ç°

Microsoft GraphRAGä»£è¡¨äº†GraphRAGæŠ€æœ¯çš„æœ€æ–°è¿›å±•ï¼Œå…¶**åˆ†å±‚ç¤¾åŒºæ£€æµ‹**å’Œ**æŸ¥è¯¢èšç„¦æ‘˜è¦**çš„åˆ›æ–°è®¾è®¡è§£å†³äº†ä¼ ç»ŸRAGçš„æ ¹æœ¬å±€é™ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‰¹æ€§

**1. è‡ªåŠ¨æç¤ºè°ƒä¼˜**

æ”¯æŒé¢†åŸŸç‰¹å®šçš„æç¤ºä¼˜åŒ–ï¼Œæé«˜æŠ½å–è´¨é‡ï¼š

```python
# GraphRAGçš„è‡ªåŠ¨æç¤ºè°ƒä¼˜ç¤ºä¾‹
from graphrag.prompt_tune import PromptTuner

# åˆå§‹åŒ–æç¤ºè°ƒä¼˜å™¨
tuner = PromptTuner(
    domain="æŠ€æœ¯æ–‡æ¡£",
    language="ä¸­æ–‡",
    examples=domain_examples
)

# ç”Ÿæˆä¼˜åŒ–çš„æç¤º
entity_extraction_prompt = tuner.generate_entity_prompt()
relation_extraction_prompt = tuner.generate_relation_prompt()
```

**2. å±‚æ¬¡åŒ–ç¤¾åŒºç»“æ„**

```python
# ç¤¾åŒºæ£€æµ‹é…ç½®
community_config = {
    "algorithm": "leiden",
    "resolution": [0.1, 0.5, 1.0],  # å¤šåˆ†è¾¨ç‡
    "iterations": 10,
    "random_seed": 42
}

# æ„å»ºå±‚æ¬¡åŒ–ç¤¾åŒº
communities = build_hierarchical_communities(
    graph=knowledge_graph,
    config=community_config
)

# ä¸ºæ¯ä¸ªå±‚çº§ç”Ÿæˆæ‘˜è¦
for level, community_data in communities.items():
    summaries = generate_community_summaries(
        community_data,
        llm=llm,
        max_tokens=500
    )
```

**3. æŸ¥è¯¢èšç„¦æ‘˜è¦**

```python
def query_focused_summarization(query, communities, llm):
    """
    æŸ¥è¯¢èšç„¦çš„ç¤¾åŒºæ‘˜è¦ç”Ÿæˆ
    """
    relevant_communities = []
    
    # è¯†åˆ«ç›¸å…³ç¤¾åŒº
    for community_id, entities in communities.items():
        relevance_score = calculate_relevance(query, entities)
        if relevance_score > threshold:
            relevant_communities.append((community_id, relevance_score))
    
    # ç”ŸæˆæŸ¥è¯¢èšç„¦æ‘˜è¦
    summaries = []
    for community_id, score in relevant_communities:
        community_context = get_community_context(community_id)
        
        prompt = f"""
        åŸºäºä»¥ä¸‹ç¤¾åŒºä¿¡æ¯ï¼Œé’ˆå¯¹æŸ¥è¯¢"{query}"ç”Ÿæˆç›¸å…³æ‘˜è¦ï¼š
        
        ç¤¾åŒºå®ä½“ï¼š{community_context['entities']}
        ç¤¾åŒºå…³ç³»ï¼š{community_context['relationships']}
        
        é‡ç‚¹å…³æ³¨ä¸æŸ¥è¯¢ç›¸å…³çš„ä¿¡æ¯ï¼Œç”Ÿæˆç®€æ´å‡†ç¡®çš„æ‘˜è¦ã€‚
        """
        
        summary = llm.generate(prompt)
        summaries.append({
            'community_id': community_id,
            'summary': summary,
            'relevance': score
        })
    
    return summaries
```

**4. æˆæœ¬ä¼˜åŒ–è®¾è®¡**

é€šè¿‡ç¤¾åŒºæ‘˜è¦æ˜¾è‘—å‡å°‘tokenä½¿ç”¨é‡ï¼š

```python
# æˆæœ¬ä¼˜åŒ–çš„æŸ¥è¯¢å¤„ç†
def cost_optimized_query(query, graph_data, budget_tokens=10000):
    """
    æˆæœ¬ä¼˜åŒ–çš„æŸ¥è¯¢å¤„ç†
    """
    # ä¼°ç®—tokenä½¿ç”¨é‡
    estimated_tokens = estimate_token_usage(query, graph_data)
    
    if estimated_tokens <= budget_tokens:
        # ç›´æ¥å¤„ç†
        return standard_graphrag_query(query, graph_data)
    else:
        # ä½¿ç”¨ç¤¾åŒºæ‘˜è¦å‡å°‘æˆæœ¬
        community_summaries = get_community_summaries(graph_data)
        compressed_context = compress_context(
            community_summaries, 
            target_tokens=budget_tokens * 0.8
        )
        return summary_based_query(query, compressed_context)
```

#### å·¥ä¸šçº§å·¥ä½œæµ

Microsoft GraphRAGåŸºäºDataShaperæä¾›å®Œæ•´çš„æ•°æ®å¤„ç†æµæ°´çº¿ï¼š

```yaml
# GraphRAGå·¥ä½œæµé…ç½®ç¤ºä¾‹
stages:
  - name: "text_preprocessing"
    type: "text_splitter"
    config:
      chunk_size: 1200
      chunk_overlap: 100
      
  - name: "entity_extraction"
    type: "llm_entity_extractor"
    config:
      model: "gpt-4"
      temperature: 0.1
      max_tokens: 2000
      
  - name: "relation_extraction"
    type: "llm_relation_extractor"
    config:
      model: "gpt-4"
      relationship_types: ["RELATED_TO", "PART_OF", "INFLUENCES"]
      
  - name: "graph_construction"
    type: "graph_builder"
    config:
      entity_similarity_threshold: 0.8
      relation_confidence_threshold: 0.7
      
  - name: "community_detection"
    type: "leiden_clustering"
    config:
      resolution: [0.1, 0.5, 1.0]
      max_iterations: 10
      
  - name: "summary_generation"
    type: "community_summarizer"
    config:
      max_summary_length: 500
      focus_entities: true
```

#### æ€§èƒ½è¡¨ç°çªå‡º

åœ¨RobustQAåŸºå‡†æµ‹è¯•ä¸­çš„è¡¨ç°ï¼š

| æ–¹æ³• | å‡†ç¡®ç‡ | å“åº”æ—¶é—´ | Tokenä½¿ç”¨é‡ |
|------|--------|----------|-------------|
| ä¼ ç»ŸRAG | 65.2% | 0.8s | 100% |
| GraphRAG | 86.3% | 0.6s | 65% |
| Microsoft GraphRAG | 89.1% | 0.5s | 45% |

> **ğŸ“Š æ€§èƒ½è¯´æ˜**ï¼šMicrosoft GraphRAGé€šè¿‡ç¤¾åŒºæ‘˜è¦æŠ€æœ¯æ˜¾è‘—å‡å°‘äº†tokenä½¿ç”¨é‡ï¼ŒåŒæ—¶ä¿æŒäº†æ›´é«˜çš„å‡†ç¡®ç‡ã€‚

### å·¥å…·é€‰æ‹©ä¸é›†æˆå»ºè®®

#### ä¸åŒåœºæ™¯çš„æœ€ä½³é€‰æ‹©

**åˆå­¦è€…é¡¹ç›®ï¼šLangChain + Neo4j Aura**

```python
# å¿«é€Ÿå…¥é—¨é…ç½®
from langchain_community.graphs import Neo4jGraph

# è¿æ¥åˆ°Neo4j Auraï¼ˆäº‘æœåŠ¡ï¼‰
graph = Neo4jGraph(
    url="neo4j+s://your-instance.databases.neo4j.io",
    username="neo4j",
    password="your-password"
)

# ä½¿ç”¨LangChainå¿«é€Ÿæ„å»º
transformer = LLMGraphTransformer(llm=llm)
qa_chain = GraphCypherQAChain.from_llm(llm, graph)
```

**ä¼˜åŠ¿**ï¼š
- æ–‡æ¡£å®Œå–„ã€å­¦ä¹ æˆæœ¬ä½
- äº‘æœåŠ¡å…è¿ç»´
- ç¤¾åŒºæ´»è·ƒã€é—®é¢˜å®¹æ˜“è§£å†³

**é€‚ç”¨åœºæ™¯**ï¼šæ¦‚å¿µéªŒè¯ã€å°è§„æ¨¡åº”ç”¨ã€å­¦ä¹ ç ”ç©¶

**ä¼ä¸šçº§åº”ç”¨ï¼šNeo4j Enterprise + è‡ªå®šä¹‰GraphRAG**

```python
# ä¼ä¸šçº§é…ç½®
class EnterpriseGraphRAG:
    def __init__(self):
        self.graph = Neo4jGraph(
            url="bolt://neo4j-cluster.internal:7687",
            username=os.getenv("NEO4J_USER"),
            password=os.getenv("NEO4J_PASSWORD"),
            database="production"
        )
        self.setup_security()
        self.setup_monitoring()
    
    def setup_security(self):
        # é…ç½®è®¿é—®æ§åˆ¶
        self.graph.query("""
        CREATE ROLE IF NOT EXISTS analyst;
        GRANT MATCH ON GRAPH * NODES * TO analyst;
        GRANT MATCH ON GRAPH * RELATIONSHIPS * TO analyst;
        """)
    
    def setup_monitoring(self):
        # é…ç½®æ€§èƒ½ç›‘æ§
        self.metrics_collector = MetricsCollector()
        self.alert_manager = AlertManager()
```

**ä¼˜åŠ¿**ï¼š
- é«˜æ€§èƒ½ã€ä¼ä¸šçº§å®‰å…¨
- ä¸“ä¸šæŠ€æœ¯æ”¯æŒ
- å®Œæ•´çš„è¿ç»´å·¥å…·é“¾

**é€‚ç”¨åœºæ™¯**ï¼šç”Ÿäº§ç¯å¢ƒã€å¤§è§„æ¨¡éƒ¨ç½²ã€å…³é”®ä¸šåŠ¡åº”ç”¨

**ç ”ç©¶ä¸å®éªŒï¼šMicrosoft GraphRAG + è‡ªå®šä¹‰ä¼˜åŒ–**

```python
# ç ”ç©¶ç¯å¢ƒé…ç½®
from graphrag import GraphRAGConfig, GraphRAGPipeline

config = GraphRAGConfig(
    # å®éªŒæ€§é…ç½®
    entity_extraction_model="gpt-4-turbo",
    community_detection_algorithm="leiden",
    enable_experimental_features=True,
    
    # è‡ªå®šä¹‰ä¼˜åŒ–
    custom_embeddings_model="your-fine-tuned-model",
    custom_prompt_templates="domain-specific-prompts.yaml"
)

pipeline = GraphRAGPipeline(config)
```

**ä¼˜åŠ¿**ï¼š
- å‰æ²¿æŠ€æœ¯ã€å­¦æœ¯æ”¯æŒ
- å¼€æºé€æ˜ã€å¯æ·±åº¦å®šåˆ¶
- æŒç»­æ›´æ–°çš„ç ”ç©¶æˆæœ

**é€‚ç”¨åœºæ™¯**ï¼šç®—æ³•ç ”ç©¶ã€æ€§èƒ½ä¼˜åŒ–ã€æŠ€æœ¯åˆ›æ–°

#### æŠ€æœ¯æ ˆç»„åˆå»ºè®®

**ç»„åˆ1ï¼šå…¨å¼€æºæ–¹æ¡ˆ**
```
LangChain + Neo4j Community + OpenAI API
â”œâ”€â”€ ä¼˜ç‚¹ï¼šæˆæœ¬å¯æ§ã€æŠ€æœ¯æ ˆå¼€æ”¾
â””â”€â”€ é€‚åˆï¼šä¸­å°é¡¹ç›®ã€å¿«é€ŸéªŒè¯
```

**ç»„åˆ2ï¼šæ··åˆäº‘æ–¹æ¡ˆ**
```
Microsoft GraphRAG + Neo4j Aura + Azure OpenAI
â”œâ”€â”€ ä¼˜ç‚¹ï¼šæ‰˜ç®¡æœåŠ¡ã€ä¼ä¸šçº§æ”¯æŒ
â””â”€â”€ é€‚åˆï¼šä¼ä¸šåº”ç”¨ã€ç¨³å®šè¿è¡Œ
```

**ç»„åˆ3ï¼šå®Œå…¨è‡ªå»ºæ–¹æ¡ˆ**
```
è‡ªå®šä¹‰GraphRAG + Neo4j Enterprise + ç§æœ‰åŒ–LLM
â”œâ”€â”€ ä¼˜ç‚¹ï¼šæ•°æ®å®‰å…¨ã€å®Œå…¨å¯æ§
â””â”€â”€ é€‚åˆï¼šé‡‘èã€æ”¿åºœã€å¤§å‹ä¼ä¸š
```

## å®é™…éƒ¨ç½²æ¶æ„è®¾è®¡

### å¾®æœåŠ¡æ¶æ„

```python
# GraphRAGå¾®æœåŠ¡æ¶æ„ç¤ºä¾‹
class GraphRAGService:
    def __init__(self):
        self.knowledge_service = KnowledgeGraphService()
        self.retrieval_service = RetrievalService()
        self.generation_service = GenerationService()
        self.cache_service = CacheService()
    
    async def process_query(self, query: str):
        # æŸ¥è¯¢è·¯ç”±
        query_type = await self.classify_query(query)
        
        # æ£€æŸ¥ç¼“å­˜
        cached_result = await self.cache_service.get(query)
        if cached_result:
            return cached_result
        
        # æ‰§è¡Œæ£€ç´¢
        if query_type == "multi_hop":
            context = await self.retrieval_service.graph_search(query)
        elif query_type == "global":
            context = await self.retrieval_service.global_search(query)
        else:
            context = await self.retrieval_service.hybrid_search(query)
        
        # ç”Ÿæˆå›ç­”
        result = await self.generation_service.generate(query, context)
        
        # ç¼“å­˜ç»“æœ
        await self.cache_service.set(query, result)
        
        return result
```

### å®¹å™¨åŒ–éƒ¨ç½²

```dockerfile
# GraphRAGæœåŠ¡Dockerfile
FROM python:3.11-slim

WORKDIR /app

# å®‰è£…ä¾èµ–
COPY requirements.txt .
RUN pip install -r requirements.txt

# å¤åˆ¶ä»£ç 
COPY src/ ./src/
COPY config/ ./config/

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PYTHONPATH=/app/src
ENV NEO4J_URI=bolt://neo4j:7687

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:8000/health || exit 1

# å¯åŠ¨æœåŠ¡
CMD ["python", "src/main.py"]
```

```yaml
# docker-compose.yml
version: '3.8'
services:
  neo4j:
    image: neo4j:5.0-enterprise
    environment:
      NEO4J_AUTH: neo4j/password
      NEO4J_PLUGINS: '["apoc", "graph-data-science"]'
    volumes:
      - neo4j_data:/data
    ports:
      - "7474:7474"
      - "7687:7687"

  graphrag-api:
    build: .
    environment:
      NEO4J_URI: bolt://neo4j:7687
      OPENAI_API_KEY: ${OPENAI_API_KEY}
    depends_on:
      - neo4j
    ports:
      - "8000:8000"

  redis:
    image: redis:7-alpine
    volumes:
      - redis_data:/data

volumes:
  neo4j_data:
  redis_data:
```

## å°ç»“

æœ¬æ–‡è¯¦ç»†åˆ†æäº†GraphRAGçš„ä¸»æµå·¥å…·æ¡†æ¶ï¼ŒåŒ…æ‹¬Neo4jã€LangChainå’ŒMicrosoft GraphRAGçš„ç‰¹ç‚¹å’Œåº”ç”¨åœºæ™¯ã€‚é€‰æ‹©åˆé€‚çš„å·¥å…·æ¡†æ¶å¯¹äºGraphRAGé¡¹ç›®çš„æˆåŠŸè‡³å…³é‡è¦ã€‚

**å·¥å…·é€‰æ‹©è¦ç‚¹å›é¡¾**ï¼š
- âœ… Neo4jæä¾›ä¼ä¸šçº§å›¾æ•°æ®åº“èƒ½åŠ›ï¼Œé€‚åˆç”Ÿäº§ç¯å¢ƒ
- âœ… LangChainç®€åŒ–å¼€å‘æµç¨‹ï¼Œé€‚åˆå¿«é€ŸåŸå‹å’Œå­¦ä¹ 
- âœ… Microsoft GraphRAGä»£è¡¨æŠ€æœ¯å‰æ²¿ï¼Œé€‚åˆç ”ç©¶å’Œåˆ›æ–°
- âœ… æ ¹æ®é¡¹ç›®è§„æ¨¡å’Œéœ€æ±‚é€‰æ‹©åˆé€‚çš„æŠ€æœ¯æ ˆç»„åˆ

**ä¸‹æœŸé¢„å‘Š**ï¼šã€ŠGraphRAG å®Œæ•´å…¥é—¨æŒ‡å—ï¼ˆå››ï¼‰ï¼šåº”ç”¨å®è·µä¸å­¦ä¹ è·¯å¾„ã€‹å°†é€šè¿‡å…·ä½“çš„åº”ç”¨æ¡ˆä¾‹å’Œç³»ç»Ÿæ€§çš„å­¦ä¹ è®¡åˆ’ï¼Œå¸®åŠ©ä½ æŒæ¡GraphRAGçš„å®é™…åº”ç”¨ã€‚ 